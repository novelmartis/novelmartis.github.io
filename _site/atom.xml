<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>martis.</title>
 <link href="http://novelmartis.github.io/atom.xml" rel="self"/>
 <link href="http://novelmartis.github.io/"/>
 <updated>2017-10-02T16:47:23+02:00</updated>
 <id>http://novelmartis.github.io</id>
 <author>
   <name>‘Sushrut Thorat’</name>
   <email></email>
 </author>

 
 <entry>
   <title>Thoughts about the 1st Brain Twitter Conference</title>
   <link href="http://novelmartis.github.io/2017/05/27/twitter-conference/"/>
   <updated>2017-05-27T00:00:00+02:00</updated>
   <id>http://novelmartis.github.io/2017/05/27/twitter-conference</id>
   <content type="html">&lt;p&gt;&lt;em&gt;I presented &lt;a href=&quot;https://twitter.com/abc_aalto/status/855043613453058048&quot;&gt;my work&lt;/a&gt; at the 1st Brain Twitter Conference, hosted by the Aalto Brain Centre. Here are my thoughts about the experience.&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;Briefing&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://storify.com/abc_aalto/brain-twitter-conference-braintc&quot;&gt;1&lt;sup&gt;st&lt;/sup&gt; Brain Twitter Conference&lt;/a&gt; was hosted on Twitter on the 20th of April, 2017. The conference events consisted of Twitter &amp;quot;talks&amp;quot; (let&amp;#39;s call them Twalks). Each twalk had the structure:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Announcement tweet of the twalk by the &lt;a href=&quot;https://twitter.com/abc_aalto&quot;&gt;Aalto Brain Centre&lt;/a&gt;, who acted as the chair.&lt;/li&gt;
&lt;li&gt;A string of &lt;em&gt;n&lt;/em&gt; tweets by the presenter (with images/gifs/videos attached)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There were two types of twalks - presentations and keynotes. Each presentation consisted of 6 tweets by the presenter, and the keynote consisted of 10 tweets. Each presentation was allotted 15 minutes for the tweet delivery while the keynotes lasted 30 minutes. During the presentation and the keynotes, others were free to ask questions, and all the proceedings were recorded under the hashtag &lt;a href=&quot;https://twitter.com/search?vertical=default&amp;amp;q=%23braintc&amp;amp;src=typd&amp;amp;lang=en&quot;&gt;#brainTC&lt;/a&gt;. Aalto Brain Centre retweeted the tweets of the twalks so one could easily cut through the comments and follow the twalks.&lt;/p&gt;

&lt;p&gt;Ckeck out the &lt;a href=&quot;https://storify.com/abc_aalto/brain-twitter-conference-braintc&quot;&gt;Storify&lt;/a&gt; of the conference.&lt;/p&gt;

&lt;h2&gt;Thoughts about the Conference&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Condensing your work to 6 tweets seems like an impossibility, but the conference showed that it is possible without toning down scientific rigour. Images become extremely important and need to stand their own ground. Using images directly from your publication seems tempting, but the captions seem cumbersome. The focus should be on the pictorial flow of ideas within the image. It wasn&amp;#39;t an easy task for me (took a week and multiple discussions with the team to get things right). It was fun.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://twitter.com/search?vertical=default&amp;amp;q=%23braintc&amp;amp;src=typd&amp;amp;lang=en&quot;&gt;#braintc&lt;/a&gt; was abuzz with discussions. There weren&amp;#39;t many well-known names. Maybe they were merely spectating. It somehow felt like the initial outreach of the conference was not sufficient to capture the attention of well-known researchers. I guess after the success of this edition, the next edition will enjoy a wider group of participants. Given the ease (?) of organising, compared to other conferences, I guess we should have two or three Brain Twitter Conferences in a year. It was awesome of the &lt;a href=&quot;https://twitter.com/abc_aalto&quot;&gt;Aalto Brain Centre&lt;/a&gt; to host the first edition, but if we are to host multiple conferences in a year, other research groups should pick up the torch.&lt;/li&gt;
&lt;li&gt;We had a nice &lt;a href=&quot;https://twitter.com/Neuro_Skeptic/status/855010583166496768&quot;&gt;discussion&lt;/a&gt; about the importance of scientific blogging as a part of PhD training. Most research is highly specific. Viewing the work in a broader perspective would be useful to us as scientists and would make it easier for the public to understand what we are doing. That discussion got me thinking - it wouldn&amp;#39;t be a bad idea to host panel discussions on such topics as a part of the conference. The organiser&amp;#39;s Twitter handle could tweet about the issue/idea, and the discussion could follow as replies to that tweet creating a tree under that tweet. That could be tried in the next edition. We could also have a dedicated event where people provide general introductions to new ideas, which might be half-baked, and could receive feedback about them from the community.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All in all, it was an enjoyable experience. I remember people being skeptical about this format, but it turned out fine. I am looking forward to many more of these conferences!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Building a simple Reverse Dictionary</title>
   <link href="http://novelmartis.github.io/2016/11/06/reverse-dictionary/"/>
   <updated>2016-11-06T00:00:00+01:00</updated>
   <id>http://novelmartis.github.io/2016/11/06/reverse-dictionary</id>
   <content type="html">&lt;p&gt;&lt;em&gt;The associated COLING&amp;#39;16 paper can be accessed on &lt;a href=&quot;https://arxiv.org/abs/1606.00025&quot;&gt;arXiv&lt;/a&gt;. Setting a new baseline for phrasal semantics processing. The test dataset and sample code can be found on &lt;a href=&quot;https://github.com/novelmartis/RD16demo&quot;&gt;Github&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;h4&gt;Motivation &amp;amp; Idea:&lt;/h4&gt;

&lt;p&gt;We often can&amp;#39;t find single words to describe our thoughts, but we can describe the concepts in phrases. A Reverse Dictionary (RD) is a solution to this problem. A normal word dictionary maps words to their definitions, but a reverse dictionary maps phrases to semantically-similar words.&lt;/p&gt;

&lt;p&gt;This calls for the ability to parse phrases semantically. Now, similarities between words have been studied &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1002/lnco.362/abstract&quot;&gt;extensively&lt;/a&gt;. These similarities usually rely on a representational space of words, such as &lt;a href=&quot;http://papers.nips.cc/paper/5021-distributed-representations&quot;&gt;word2vec&lt;/a&gt; (constructed by crawling a huge corpus and extracting the contextual similarities between words, which also reflects the semantics). There isn&amp;#39;t such a representational formalism, which encodes phrasal semantics,  available for phrases. Maybe vectors aren&amp;#39;t suitable for phrasal representations anyway, and we should look towards &lt;a href=&quot;http://www.aclweb.org/anthology/D/D10/D10-1115.pdf&quot;&gt;other mathematical structures&lt;/a&gt;, or we should just use sequential parsing while encoding relationships between constituents - as in a &lt;a href=&quot;http://www.aclweb.org/anthology/Q16-1002&quot;&gt;RNN&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The methods just mentioned are the logical steps forward. Once we understand how to represent phrasal semantics, linking it to lexical semantics won&amp;#39;t be hard, thus solving the reverse dictionary problem, hopefully. But there are other &lt;a href=&quot;http://www.oxfordlearnersdictionaries.com/definition/english/jugaad_1?q=jugaad&quot;&gt;jugaad&lt;/a&gt; that could have simple implementations and could already provide excellent performance for a reverse dictionary. The naivest method is to count to number of words in the input phrase which appear in each word&amp;#39;s definition, and use that as a similarity score from the phrase to every word in the lexicon. As you can tell, this method won&amp;#39;t perform very well. &lt;/p&gt;

&lt;p&gt;This approach can be modified to search for lexical relatives of the words in the input phrase and match them with the definitions of the words in the lexicon towards defining a similarity measure. Factors such as frequencies of words (which might distort the similarity measure) appearing in definitions can be taken care of. The word order in the phrase can be factored in by assessing the words&amp;#39; positions in the constitutent tree of the phrase. Negation words, such as &lt;em&gt;not&lt;/em&gt;, can be used as indications to change the constituents following the negation words to their antonyms. All these additions were made by &lt;a href=&quot;http://ieeexplore.ieee.org/document/6060823/&quot;&gt;Shaw, R., et.al.&lt;/a&gt; in their 2013 model, which performed better than the well-known proprietary software, the &lt;a href=&quot;http://www.onelook.com/reverse-dictionary.shtml&quot;&gt;Onelook Reverse Dictionary&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now, I am crazy about neural networks. So, this is what I thought - going from the words in the input phrase to the words in whose definitions they were contained, why should one not carry on from those words to the words in whose definitions they lie in, and so on, building a graph out of the entire lexicon? This &lt;em&gt;Reverse Mapping&lt;/em&gt; is the central idea of our approach. It has the intuitive appeal of word meanings converging/composing in a meaningful way onto other words. Of course, for one sensible convergence, there maybe tens of nonsensical covergences. This indeed is a naive approach and we wanted to see how well it could perform (The rationale was - the RD could output tens of words, and all that matters is that the target word be present in there. We could later think of some learning protocol which could selectively enhance connections, something we didn&amp;#39;t get down to).&lt;/p&gt;

&lt;h4&gt;The Approach:&lt;/h4&gt;

&lt;p&gt;As shown in the figure below,&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://www.psych.nyu.edu/pylkkanen/Neural_Bases/13_Function_Words.pdf&quot;&gt;Functional/stop words&lt;/a&gt; are removed from the input phrase. &lt;/li&gt;
&lt;li&gt;The remaining &lt;em&gt;content words&lt;/em&gt; are converted to their base forms using a lemmatiser.&lt;/li&gt;
&lt;li&gt;These &lt;em&gt;input words&lt;/em&gt; are activated on the reverse map constructed using one/many dictionaries.&lt;/li&gt;
&lt;li&gt;The graph is evolved until all words are reached by the signals from each input word

&lt;ul&gt;
&lt;li&gt;To ensure that all words are connected to every other word, we incorporate forward links (word to words contained in its definition) from the words who do not possess sufficient connectivity. This &lt;em&gt;modified&lt;/em&gt; graph&amp;#39;s connectivity is given by the mixed-backlinked-matrix (mBLM), in the paper.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;We thus have a measure of &lt;em&gt;distances&lt;/em&gt; between the input words and words in the lexicon. We then deploy the similarity measure to get the similarity between the input phrase and the words in the lexicon. &lt;/li&gt;
&lt;li&gt;The similarity measure &lt;em&gt;E(W,P)&lt;/em&gt; of a word &lt;em&gt;W&lt;/em&gt; to the input phrase &lt;em&gt;P&lt;/em&gt; is given by, $$\text{E}&lt;em&gt;{W,P} =\frac{\sum&lt;/em&gt;i \left ( \nu&lt;em&gt;{P&lt;/em&gt;i}\times d&lt;em&gt;{W,P&lt;/em&gt;i} \right )^{-1}}{\sum&lt;em&gt;i \nu&lt;/em&gt;{P_i}^{-1}}$$, where &lt;em&gt;ν&lt;/em&gt; denotes the frequency of appearance in word definitions, and &lt;em&gt;d&lt;/em&gt; the distance on the graph.&lt;/li&gt;
&lt;li&gt;All the words in the lexicon are ranked according to their similarity measures, and outputted.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;http://novelmartis.github.io/assets/RD_sum.png&quot; alt=&quot;Summary of the Approach&quot;&gt;&lt;/p&gt;

&lt;p&gt;As seen in the figure, the input phrase &amp;#39;Son of my parents&amp;#39; does lead to the word &amp;#39;brother&amp;#39; (the target) as a high-ranked candidate output. As can be seen, the approach is pretty naive, and performs a shallow extraction of useful semantics. Let&amp;#39;s see anyway how it compares to the state-of-the-art approaches.&lt;/p&gt;

&lt;h4&gt;Testing procedure:&lt;/h4&gt;

&lt;p&gt;On the lines of &lt;a href=&quot;http://www.aclweb.org/anthology/Q16-1002&quot;&gt;Hill, F., et.al.&lt;/a&gt;, we decided to create a dataset of user-generated phrases given target words. We had to create a new database as we were using a smaller lexicon (3k words) for the first phase of our project. 25 users generated 179 phrases for us. The performance of a reverse dictionary is given by the rank of the target word in its outputs, given an input phrase. We also extracted definitions for those 179 target words from the Macmillian word dictionary - which we did not use in building out graph.&lt;/p&gt;

&lt;h4&gt;Results and Conclusions:&lt;/h4&gt;

&lt;p&gt;For the user-generated phrases, our best model could find the target word in 10% (top-10 outputs), and 53% (top-100 outputs) of the cases, as opposed to 7% (top-10 outputs), and 52% (top-100 outputs) for Onelook. For the Macmillian word definitions, our best model could find the target word in 25% (top-10 outputs), and 84% (top-100 outputs) of the cases, as opposed to 20% (top-10 outputs), and 68% (top-100 outputs) for Onelook. If we were to generate a random selection of words, we could find the target word in 0.01% (top-10 outputs), and 3% (top-100 outputs) of the cases. So, our approach is actually performing well (sanity-check).&lt;/p&gt;

&lt;p&gt;So, our approach performed atleast as well as the &lt;a href=&quot;http://www.onelook.com/reverse-dictionary.shtml&quot;&gt;Onelook Reverse Dictionary&lt;/a&gt; on the 179 user-generated phrases and Macmillian word definitions. We also compared our approach with Onelook on the 200 phrases provided by &lt;a href=&quot;http://www.aclweb.org/anthology/Q16-1002&quot;&gt;Hill, F., et.al.&lt;/a&gt;, and our approach performed atleast as well. Now, the RNN-based approach used by &lt;a href=&quot;http://www.aclweb.org/anthology/Q16-1002&quot;&gt;Hill, F., et.al.&lt;/a&gt; performed only slightly better than Onelook. This implies that the semantics being processed by the RNNs are pretty shallow (as the performance is comparable to our naive approach). &lt;/p&gt;

&lt;p&gt;Our approach doesn&amp;#39;t scale well to a bigger lexicon, as seen in the paper. It nevertheless is a cheap way of converting any dictionary into a reverse dictionary. Our method, and that of &lt;a href=&quot;http://ieeexplore.ieee.org/document/6060823/&quot;&gt;Shaw, R., et.al&lt;/a&gt;, could be treated as baselines in the sense that we know how shallow the semantic processing is. The way forward, of course, are RNNs and other semi/un-supervised architectures, which could extract their own features, and which could settle on novel mathematical structures. The performance baselines provided in our paper could be used as a sanity-check for deep semantic processing in the newer architectures.&lt;/p&gt;

&lt;h4&gt;Acknowledgement:&lt;/h4&gt;

&lt;p&gt;The &amp;quot;we&amp;quot; here - &lt;a href=&quot;https://twitter.com/askvarad&quot;&gt;Varad Choudhari&lt;/a&gt; and me. He took care of all the computational heavylifting. Kudos to him!&lt;/p&gt;

&lt;p&gt;I would like to thank &lt;a href=&quot;https://twitter.com/IonutSorodoc&quot;&gt;Ionut-Teodor Sorodoc&lt;/a&gt;, &lt;a href=&quot;https://www.quora.com/profile/Arpan-Saha&quot;&gt;Arpan Saha&lt;/a&gt;, &lt;a href=&quot;http://www.synapticlee.co.uk/about/&quot;&gt;Julie Lee&lt;/a&gt;, and &lt;a href=&quot;https://www5.unitn.it/People/en/Web/Persona/PER0001015#INFO&quot;&gt;Prof. Roberto Zamparelli&lt;/a&gt; for making useful comments about the project, and the 25 participants who generated the phrases.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Visual infomation processing with biologically-realistic neural networks - Musings</title>
   <link href="http://novelmartis.github.io/2016/07/31/visual-processing-review/"/>
   <updated>2016-07-31T00:00:00+02:00</updated>
   <id>http://novelmartis.github.io/2016/07/31/visual-processing-review</id>
   <content type="html">&lt;h2&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Vision for us is so natural, rapid and effortless. But how do we recognise a cat as a cat? We might be identifying multiple features such as its ears, its nose, its shape and size. We might have a template for a cat in our brains, with which we match the input image. Template matching sounds promising but is a procedure that is ridiculously complex. For example, what would the template of a cat contain, and how would the images in the figure below be comparable to that template? &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://novelmartis.github.io/assets/cats_all.png&quot; alt=&quot;Template of a cat?&quot; title=&quot;Template of a cat?&quot;&gt;&lt;/p&gt;

&lt;p&gt;There are two routes to go from these images to the template:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Non-linear 3D spatial transformations and non-linear transformations on color intensities.

&lt;ul&gt;
&lt;li&gt;Distorting the image and changing the color profile to fit the template.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Recognise individual features (ears, eyes, etc.) in those images and build the template using them.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The first route can encompass the second, as individual feature recognisers could be treated as non-linear transformations on the pixel map. Handpicked features do not provide optimal performance, making the first route the choice for exploring visual information processing. &lt;/p&gt;

&lt;p&gt;We might be employing a complex template matching approach, but stating that isn&amp;#39;t enough. How do we implement these non-linear transformations? How does a network of neurons implement object recognition? This problem is being solved using the mathematical, algorithmic and neuroscience perspectives. The objective is to understand how a biologically-realistic neural network could implement visual information processing.&lt;/p&gt;

&lt;p&gt;This could be a line-of-attack: &lt;br&gt;&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-&quot; data-lang=&quot;&quot;&gt;Visual information processing with biologically-realistic SNNs
├── The problem
├── Previous Work
│   ├── Outline
│   ├── Computer Vision
│   │   └── CNNs, RNNs, etc
│   ├── Biological Modelling
│   │   └── HMAX, etc
│   ├── SNNs
│   └── Additions to the problem
│       └── Unsupervised learning
├── Working with SNNs
│   ├── Architectural constraints
│   │   ├── Operational principles: tight E-I balance, etc.
│   │   └── Neural models - Simplicity vs Accuracy
│   └── Learning Rules
│       ├── ReSuMe, etc
│       ├── Backpropagation modified?
│       └── Other rules? - Explore
└── Further work
    ├── Deciding the learning rules
    └── Generalising to videos, attention, etc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Let's get it started!</title>
   <link href="http://novelmartis.github.io/2016/07/12/getting-started/"/>
   <updated>2016-07-12T00:00:00+02:00</updated>
   <id>http://novelmartis.github.io/2016/07/12/getting-started</id>
   <content type="html">&lt;p&gt;&lt;em&gt;The stage is set. Time to roll..&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Only if life were so. The stage is seldom &lt;em&gt;set&lt;/em&gt;. One should keep rolling though.. or atleast think so. Too philosophical a start!&lt;/p&gt;

&lt;p&gt;I&amp;#39;ll pull in some of my past blog posts, which are scattered all over the place. Then, hopefully, I will keep up the momentum. x&lt;/p&gt;

&lt;p&gt;I&amp;#39;ll eventually add in the project details too.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Arithmetic computations with Spiking Neural Networks</title>
   <link href="http://novelmartis.github.io/2016/06/09/arithmetic-computation/"/>
   <updated>2016-06-09T00:00:00+02:00</updated>
   <id>http://novelmartis.github.io/2016/06/09/arithmetic-computation</id>
   <content type="html">&lt;p&gt;&lt;em&gt;This one dates back to 2015. It was a part of my Bachelor’s thesis. But this part has applications beyond the objective of the thesis viz. quadcopter control. We published a paper detailing our method. It is available &lt;a href=&quot;http://dx.doi.org/10.1109/IJCNN.2015.7280822&quot;&gt;here&lt;/a&gt; (&lt;a href=&quot;https://www.academia.edu/20315873/Arithmetic_Computing_via_Rate_Coding_in_Neural_Circuits_with_Spike-triggered_Adaptive_Synapses&quot;&gt;open-access&lt;/a&gt;). Note: The description below is a simplistic version of what was done in the paper. All the operations mentioned use well-defined mathematical rules.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Spiking_neural_network&quot;&gt;Spiking Neural Networks&lt;/a&gt; are approximations of &lt;a href=&quot;https://en.wikipedia.org/wiki/Biological_neural_network&quot;&gt;biological neural networks&lt;/a&gt;. The approximations range from neuron models to synaptic learning models to network topology. The &lt;a href=&quot;http://eaton.math.rpi.edu/CSUMS/Papers/Neuro/Izhikevich04.pdf&quot;&gt;simplest spiking neuron models&lt;/a&gt; are the LIF, AEIF, and Izhikevich neurons. They try to capture information about the spike-times, approximate the nature of the action potential, and various operational modes (burst, regular, etc.). An extremely realistic model is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Hodgkin%E2%80%93Huxley_model&quot;&gt;Hodgkin-Huxley model&lt;/a&gt;. But it is computationally-intensive, and without access to clusters you cannot simulate a network with hundreds of such neurons. Processes such as &lt;a href=&quot;http://research.mssm.edu/cnic/pdfs/nn0604-567.pdf&quot;&gt;dendritic integration&lt;/a&gt; and AP back-propagation are unaccounted for in these models. But we have to start somewhere, and we usually start simple. AEIF neurons capture many neural firing modes, and other relevant properties such as &lt;a href=&quot;http://www.bio.lmu.de/%7Ebenda/publications/adaptation03/adaptationh.html&quot;&gt;spike-frequency adaptation&lt;/a&gt; and also encode a refractory function. These are the neurons we use in our method.&lt;/p&gt;

&lt;p&gt;So, the problem was this - how can SNNs implement arithmetic operations such as Addition, Subtraction, Multiplication and Division? This turns out to be a non-trivial question. Spiking neurons have non-linear I-O relationships (logarithmic &lt;a href=&quot;ftp://ftp.icsi.berkeley.edu/pub/ai/jagota/vol2_6.pdf&quot;&gt;transfer function&lt;/a&gt;), as shown in the following figure. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://novelmartis.github.io/assets/fI_AEIF.png&quot; alt=&quot;f-I plot for AEIF neuron&quot;&gt;&lt;/p&gt;

&lt;p&gt;To implement linear operations such as addition or subtraction, we need to linearise the the transfer function. Now, we focussed on the network influences, rather than trying to &lt;a href=&quot;http://arxiv.org/pdf/1410.7881.pdf&quot;&gt;manipulate internal dynamics of neurons&lt;/a&gt;. To that end, we introduced a self-inhibitory loop that pushed the neuron into the higher current domain in the above figure, which is pretty linear. With a linear transfer function at our disposal, we can do addition and subtraction. &lt;/p&gt;

&lt;p&gt;The problem begins with multiplication. I thought about using a recurrent loop with some sort of gated function which would keep adding the same value till we ask to stop it. But then I realised there was a simpler way - use exponentiation and logarithm. &lt;/p&gt;

&lt;p&gt;Now, $$\text{A}\times\text{B}=e^{\text{log(A)} + \text{log(B)}}$$&lt;/p&gt;

&lt;p&gt;So, if we could construct networks with overall exponential and logarithmic transfer functions, we are done! We not only solve multiplication and division, but we can also create any sort of polynomial transfer function by composing appropriate LOG and EXP blocks!&lt;/p&gt;

&lt;p&gt;To implement these LOG and EXP blocks, we turned to adaptive synapses. We designed learning rules that allowed us to generate LOG and EXP responses. Simply put, to generate LOG, the synaptic weight has to decrease with increased pre-synaptic firing rate, and to generate EXP, it has to increase with increasing pre-synaptic firing rate. We then translated these rate based rules into spike-time based rules for performing real-time computations. So, we had EXP and LOG networks, which we composed to implement multiplication and division.&lt;/p&gt;

&lt;p&gt;Yes, we know how to use SNNs to implement addition, subtraction, multiplication, and division now. But there were multiple problems with the approach:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The synaptic adaptation rule was designed and doesn’t seem to be biologically realistic.&lt;/li&gt;
&lt;li&gt;The time required for the networks to stabilise their multiplicative outputs could extend to 0.5 seconds, which make them impossible to use in quick-response control systems such as the quadcopter core control, or biological systems like the cerebellum.&lt;/li&gt;
&lt;li&gt;The operational spike rates lie between 40-140 Hz, which excludes most of the biological neural rates which are pretty low.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So, this is not a biologically realistic model of arithmetic computations, and shouldn’t be treated as such.&lt;/p&gt;

&lt;p&gt;A more realistic method of implementing arithmetic operations needs to take into account the actual operational principles of biological neural networks such as &lt;a href=&quot;http://www.nature.com/neuro/journal/v19/n3/full/nn.4243.html&quot;&gt;tight E-I balance&lt;/a&gt;. There are some &lt;a href=&quot;https://papers.nips.cc/paper/5948-enforcing-balance-allows-local-supervised-learning-in-spiking-recurrent-networks.pdf&quot;&gt;efforts&lt;/a&gt; in this direction. Hopefully, we’ll get to a point where we would be able to converse fluently in neural codes.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Quadcopter control using Spiking Neural Networks</title>
   <link href="http://novelmartis.github.io/2016/06/05/quadcopter-control-using-snn/"/>
   <updated>2016-06-05T00:00:00+02:00</updated>
   <id>http://novelmartis.github.io/2016/06/05/quadcopter-control-using-snn</id>
   <content type="html">&lt;p&gt;&lt;em&gt;This one dates back to 2015. This was the topic of my bachelor’s thesis, which was admittedly left incomplete. Find the report &lt;a href=&quot;https://dx.doi.org/10.6084/m9.figshare.1582657.v1&quot;&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Spiking_neural_network&quot;&gt;Spiking Neural Networks&lt;/a&gt; hit that sweet spot between biological neural networks and artificial neural networks (although now &lt;a href=&quot;http://karpathy.github.io/2015/05/21/rnn-effectiveness/&quot;&gt;RNNs&lt;/a&gt; and &lt;a href=&quot;http://arxiv.org/abs/1605.07678&quot;&gt;CNNs&lt;/a&gt; are struggling to take over). To better understand how they function, we thought about using them to solve a well-known complex control problem - balancing and flying a quadcopter. &lt;/p&gt;

&lt;p&gt;The first step was to understand quadcopter flight dynamics. The quadcopter is inherently an unstable system - the smallest uncorrected angular deviation in pitch can send the quadcopter flying out of control. PIDs (compensatory mechanisms that worked by controlling the four rotors) were simple and efficient solutions to this problem. In the first leg of the project, we designed a control algorithm directly taking the dynamical equations of the system into account. Our algorithm outperformed &lt;a href=&quot;https://en.wikipedia.org/wiki/PID_controller&quot;&gt;PID&lt;/a&gt;s, and could recover the quadcopter from a multitude of states (including crazy upside-down states). &lt;/p&gt;

&lt;p&gt;Having understood quadcopter dynamics, we wanted to move ahead to bring in the SNNs. The roadblock was severe. How were we supposed to use SNNs to fly a quadcopter? There were multiple options -&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Learning algorithms such as &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.6325&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;ReSuMe&lt;/a&gt;, &lt;/li&gt;
&lt;li&gt;Evolutionary methods such as &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.5457&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;NEAT&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;Hand-assembling a network,&lt;/li&gt;
&lt;li&gt;Understanding a natural control system such as the cerebellum and trying to re-purpose the mechanisms. &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(4) is a hard problem, but would definitely be interesting to address someday. We weren’t aware if somebody had used (1), but I wasn’t really impressed by the method. Also, the training would require data from the control system we developed, and we were not sure if the the algorithm would generalise and ‘go beyond’ - which would be the point of using a learning algorithm. (But maybe the ‘i-dont-like-it&amp;#39; factor weighed heavier) (2) was used in a &lt;a href=&quot;http://classes.engr.oregonstate.edu/mime/fall2010/me537/Papers/NN_EA_application_shepherd.pdf&quot;&gt;paper&lt;/a&gt; successfully, but not with SNNs (NEAT with SNNs is a computationally-heavy routine).&lt;/p&gt;

&lt;p&gt;So, were we supposed to hand-assemble the network? That sounded sour. But then my advisor hinted at building plug-and-play spiking network modules which could be assembled to emulate any control algorithm. We were focussed on the basic arithmetic operations - addition, subtraction, multiplication and division - which mostly are sufficient for implementing simple control systems. Also, the control algorithm we designed in the first leg of the project used only polynomial operations. So, we set out on this path, and we came up with a method which lets one implement any polynomial transform on real-time spike trains, and &lt;a href=&quot;http://dx.doi.org/10.1109/IJCNN.2015.7280822&quot;&gt;published a paper&lt;/a&gt; about it. (I will discuss the details in another post)&lt;/p&gt;

&lt;p&gt;It so turned out that the time lags involved in the more complex operations such as multiplication of variables raised to some power, were huge. It became extremely hard to combine the modules we designed to emulate the control algorithm we had built. By that time, my time at IIT Bombay was up, and the project was left unfinished. As tempting as the approach sounded, I now think that it wasn’t the best way to proceed.&lt;/p&gt;

&lt;p&gt;It would be interesting to get around the time lag problem, but I’d put my bets on another approach. In any case, it was an awesome experience trying to bend SNNs to our will - seems we lost.&lt;/p&gt;
</content>
 </entry>
 

</feed>
