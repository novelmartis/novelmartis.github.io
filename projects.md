---
layout: page
title: Projects
---


<p class="message">
  Find information about my current and past projects below.<br>
  My peer-reviewed and preprint publications can be found on <a href="https://scholar.google.it/citations?user=MPFzJQgAAAAJ&hl=en">Google Scholar</a>.<br>
  All my project reports and presentations are hosted at <a href="https://figshare.com/authors/Sushrut%20Thorat/522624">figshare</a>.
</p>

<h3>
<div class="p_year">
  Ongoing
</div>
</h3>

[//]: # (Project with Peelen)

<div class="p_post">
  <h3 class="p_post_h">Bodies as features in visual search</h3>
  <b>With:</b> <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> Are high-level visual features (e.g. shape) prioritised, via feature-based attention, spatially-globally? We found attentional gain modulation of the fMRI representations of body silhouettes, presented in task-irrelevant locations, in high-level visual cortex. <br>
  <b>Comments:</b> <a href = "https://www.youtube.com/watch?v=lfK4oOH0AAE">NMC'3.0 talk</a>, paper being written.
</div>

[//]: # (Project with Gen and Peelen)

<div class="p_post">
  <h3 class="p_post_h">The influence of distractor regularities on visual search</h3>
  <b>With:</b> <a href="https://scholar.google.com/citations?user=2ToC6n4AAAAJ&hl=en">Genevieve Quek</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Motivation:</b> Natural object groups (e.g. egg on egg cup) <a href="https://www.pnas.org/content/111/30/11217">have been shown</a> to enhance object search as compared to their irregular versions (e.g. egg cup on egg). We are assessing if such regularities can be learnt implicitly during the search task to increase efficiency, and how the representations of these objects change as a result of grouping.<br>
  <b>Comments:</b> Online behavioural testing and EEG experiment in progress.
</div>

[//]: # (Project with Giacomo and Tim)

<div class="p_post">
  <h3 class="p_post_h">Recurrent operations in neural networks trained to recognise objects</h3>
  <b>With:</b> <a href="https://scholar.google.co.in/citations?user=qVvqArkAAAAJ&hl=en&oi=ao">Giacomo Aldegheri</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> The recurrent connectivity in a recurrent neural network performing view invariant object categorisation, in debris, carries information about category-orthogonal object features in order to, iteratively, filter out information about the debris throughout the network.<br>
</div>

<h3>
<div class="p_year">
  2019
</div>
</h3>

[//]: # (Project with Giacomo, Peelen and Marcel)

<div class="p_post">
  <h3 class="p_post_h">The function of early task-based modulations in object detection</h3>
  <img class="p_post" src="{{site.url}}/assets/SwitchSchem.png" height="200">
  <b>With:</b> <a href="https://scholar.google.co.in/citations?user=qVvqArkAAAAJ&hl=en&oi=ao">Giacomo Aldegheri</a>, <a href="https://scholar.google.nl/citations?user=sX0ZypwAAAAJ&hl=en&oi=ao">Marcel van Gerven</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> Task-based modulation of early visual processing in neural networks alleviates subsequent capacity limits caused by task and neural constraints.  Bias/gain modulation of neural activations can be linked to tapping into a superposition of networks. Optimised neural modulations are <i>not</i> <a href="https://doi.org/10.1016/j.cub.2004.04.028">feature-similarity gain modulations</a>. <br>
  <a href="https://sushrutthorat.com/ccn18/">CCN'18 paper</a>, <a href="https://arxiv.org/abs/1907.12309">CCN'19 paper</a><br>
</div>

[//]: # (Project with Ilze, Sjoerd, and Peelen)

<div class="p_post">
  <h3 class="p_post_h">The influence of scene information on object processing</h3>
  <img class="p_post" src="{{site.url}}/assets/sc-obj.png" height="200">
  <b>With:</b> Ilze Thoonen, Sjoerd Meijer, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> Task-irrelevant scene information biases categorization response towards co-varying objects (e.g. cars on roads). However, no evidence is found, across 4 experiments, for task-irrelevant scene information boosting the sensitivity of detecting co-varying objects. Further experimentation is required for validating these observations. <br>
  <a href="https://doi.org/10.6084/m9.figshare.9804725.v2">Summary presentation</a><br>
</div>

[//]: # (Project with Peelen)

<div class="p_post">
  <h3 class="p_post_h">The nature of the animacy organization in human ventral temporal cortex</h3>
  <img class="p_post" src="{{site.url}}/assets/anim_proj.png" height="200">
  <b>With:</b> <a href="https://scholar.google.it/citations?user=5GQjAZkAAAAJ&hl=en&oi=ao">Daria Proklova</a>, <a href="https://scholar.google.nl/citations?user=v4CvWHgAAAAJ&hl=en">Daniel Kaiser</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> The animacy organisation in the ventral temporal cortex is not fully driven by visual feature differences (modelled with a CNN). It also depends on non-visual (inferred) factors such as agency (quantified through a behavioural task).<br>
  <a href="https://youtu.be/L-BZKw72Nb4?list=PL0HxeKpsusXCyMF_GfQJ0eMagKNYU79xq">CAOs'17 Talk</a>, <a href="https://doi.org/10.6084/m9.figshare.5919154.v1">Masters Thesis</a>, <a href="https://doi.org/10.7554/eLife.47142">eLife'19 paper</a>, <a href="https://doi.org/10.6084/m9.figshare.10033025.v1">CCN'19 poster</a><br>
  <b>Comments:</b> <a href="https://twitter.com/abc_aalto/status/855043613453058048?s=20">Masters thesis in brief</a>, <a href="https://twitter.com/martisamuser/status/1171381533128777728?s=20">eLife paper in brief</a><br>
</div>

{% comment %}
<div class="p_post">
  <h3 class="p_post_h">Short Project Title</h3>
  <b>With:</b> Contributors<br>
  Comments / Further links
</div>
{% endcomment %}

<h3>
<div class="p_year">
  2016
</div>
</h3>

[//]: # (Project with Varad, RD)

<div class="p_post">
  <h3 class="p_post_h">Reverse dictionary using a word-definition based graph search</h3>
  <img class="p_post" src="{{site.url}}/assets/revmap.png" height="200">
  <b>With:</b> <a href="https://www.linkedin.com/in/vardos/">Varad Choudhari</a> <br>
  <b>Summary:</b> A method to process any forward word dictionary to build a reverse dictionary, using a n-hop reverse search on a graph, through word definitions. Performs as well as the state-of-the-art on a 3k lexicon. Doesn't scale well to 80k.<br>
  <a href="https://arxiv.org/abs/1606.00025">COLING'16 Paper</a>, <a href="{{site.url}}/assets/coling2016_poster.pdf">COLING'16 Poster</a>, <a href="https://github.com/novelmartis/RD16demo">Code and Data</a><br>
  <b>Comments:</b> <a href="{{site.url}}/2016/11/06/reverse-dictionary">COLING paper in brief</a><br>
</div>

<h3>
<div class="p_year">
  2015
</div>
</h3>

[//]: # (Project with Bipin, IJCNN)

<div class="p_post">
  <h3 class="p_post_h">A Spiking Neural Network as a Quadcopter Flight Controller</h3>
  <img class="p_post" src="{{site.url}}/assets/btp.png" height="200">
  <b>With:</b> <a href="https://in.linkedin.com/in/sukanya-patil-b45009107">Sukanya Patil</a>, <a href="https://sites.google.com/site/rajendranbipin/">Bipin Rajendran</a> <br>
  <b>Summary:</b> <i>a</i>. Model-based control system for quadcopters towards velocity-waypoint navigation.<br> <i>b</i>. Modular SNNs for real-time arithmetic operations, using plastic synapses. SNNs are hard to tame!<br>
  <a href="https://dx.doi.org/10.6084/m9.figshare.1582657.v1">B.Tech. Thesis</a>, <a href="https://dx.doi.org/10.1109/IJCNN.2015.7280822">IJCNN'15 paper</a> (based on part <i>b</i>, <a href="{{site.url}}/assets/ijcnn2015_poster.pdf">IJCNN'15 Poster</a>) <br>
  <b>Comments:</b> <a href="{{site.url}}/2016/06/05/quadcopter-control-using-snn">Thesis rumination</a>, <a href="{{site.url}}/2016/06/09/arithmetic-computation">IJCNN paper in brief</a><br>
</div>

{% comment %}
<div class="p_post">
  <h3 class="p_post_h">Project Title</h3>
  <img class="p_post_i" src="http://placehold.it/200x200">
  <b>With:</b> Contributors <br>
  <b>Summary:</b><br><br><br><br><br><br>
  Publication (if any) <br>
  Comments / Further links
</div>
{% endcomment %}
