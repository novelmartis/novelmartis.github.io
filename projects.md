---
layout: page
title: Projects
---


<p class="message">
  Find information about my current and past projects below.<br>
  Where applicable, collaborators leading those projects are <b><u>highlighted</u></b>.<br>
  My peer-reviewed and preprint publications can be found on <a href="https://scholar.google.it/citations?user=MPFzJQgAAAAJ&hl=en">Google Scholar</a>.<br>
  All my project reports and presentations are hosted at <a href="https://figshare.com/authors/Sushrut%20Thorat/522624">figshare</a>.
</p>

<h3>
<div class="p_year">
  Ongoing
</div>
</h3>

[//]: # (Project with Adrien and Tim)

<div class="p_post">
  <h3 class="p_post_h">Iterative category inference in recurrent neural networks</h3>
  <b>With:</b> <a href="https://scholar.google.ch/citations?user=YA6DPIcAAAAJ&hl=en">Adrien Doerig</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> Can we see signs of iterative category inference in RNNs? What kind of shape/texture/semantic space does the inference adhere to? Does the network play 20 questions with the image? What operations in the RNN lead to these processes?<br>
</div>

[//]: # (Project with Daniel, Tim, and Peter)

<div class="p_post">
  <h3 class="p_post_h">Characterising catastrophic forgetting and finding solutions</h3>
  <b>With:</b> <a href="https://www.linkedin.com/in/daniel-anthes-680621163"><b><u>Daniel Anthes</u></b></a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a>, <a href="https://scholar.google.nl/citations?user=Ieubd0EAAAAJ&hl=en&oi=ao">Peter KÃ¶nig</a><br>
  <b>Summary:</b> What aspects of training neural networks continually leads to catastrophic forgetting? Can we find simple solutions, either bio-inspired or executable without much overhead, to workaround those aspects?
</div>

[//]: # (Project with Victoria, Daniel, Tim, and Peter, etc.)

<div class="p_post">
  <h3 class="p_post_h">Brain reading with a Transformer</h3>
  <b>With:</b> <a href="https://www.linkedin.com/in/victoria-bosch/?originalSubdomain=nl"><b><u>Victoria Bosch</u></b></a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a>, et al.<br>
  <b>Summary:</b> Using fMRI responses to natural scenes to condition the sentence generation in a Transformer, we are studying the neural underpinnings of scene semantics (objects and their relationships) encoded in natural language.<br>
</div>

[//]: # (Project with Lu-Chun and Peelen)

<div class="p_post">
  <h3 class="p_post_h">Task-dependent characteristics of neural multi-object processing</h3>
  <b>With:</b> <a href="https://scholar.google.nl/citations?hl=en&user=3Fj2iKkAAAAJ"><b><u>Lu-Chun Yeh</u></b></a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> The association between the neural processing of multi-object displays and the representations of those objects presented in isolation is task-dependent: unique associations with spatiotemporal stages of the object representations, same/different judgement - earlier, and object search - later stages in MEG/fMRI signals.<br>
  <b>Comments:</b> Paper being written.
</div>

[//]: # (Project with Surya and Peelen)

<div class="p_post">
  <h3 class="p_post_h">Size-dependence of object search templates in natural scenes</h3>
  <b>With:</b> <a href="https://scholar.google.nl/citations?hl=en&user=D0z0dcgAAAAJ"><b><u>Surya Gayet</u></b></a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a>, et al.<br>
  <b>Summary:</b> Object size varies with the location of the object in scenes. These variations get reflected in the search for that object in a given set of locations in a scene: our search is better for a smaller object further out in the scene as compared to closer in the scene.<br>
  <b>Comments:</b> Paper being written.
</div>

[//]: # (Project with Jochem, Gen, and Peelen)

<div class="p_post">
  <h3 class="p_post_h">Perception of rare inverted letters among upright ones</h3>
  <img class="p_post" src="{{site.url}}/assets/letter_illusion.png" height="200">
  <b>With:</b> <a href="https://www.linkedin.com/in/jochem-koopmans-051571236"><b><u>Jochem Koopmans</u></b></a>, <a href="https://scholar.google.com/citations?user=2ToC6n4AAAAJ&hl=en">Genevieve Quek</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> In a Sperling-like task where the letters are mostly upright, there is a general tendency to report occasionally-present and absent inverted letters as upright to the same extent. This suggests that previously reported expectation-driven illusions might be post-perceptual in nature.<br>
  <b>Comments:</b> Paper being written.
  <!-- <b>Comments:</b> <a href = "https://www.biorxiv.org/content/10.1101/2022.04.20.488921">bioRxiv'22 preprint</a>, <a href = "https://twitter.com/martisamuser/status/1518515944813101056?s=20&t=pACvyE-jT4DJB8SSwCdhaw">preprint in brief</a> -->
</div>

<h3>
<div class="p_year">
  2022
</div>
</h3>

[//]: # (Project with Gen and Peelen)

<div class="p_post">
  <h3 class="p_post_h">Statistical learning of distractor co-occurrences facilitates visual search</h3>
  <img class="p_post" src="{{site.url}}/assets/obj_grp.png" height="200">
  <b>With:</b> <a href="https://scholar.google.com/citations?user=2ToC6n4AAAAJ&hl=en">Genevieve Quek</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> Efficient visual search relies on the co-occurrence statistics of distractor shapes. Increased search efficiency among co-occurring distractors is probably driven by faster and/or more accurate rejection of a distractor's partner as a possible target.<br>
  <b>Publication:</b> <a href = "https://doi.org/10.1167/jov.22.10.2">JOV'22 paper</a><br>
  <b>Comments:</b> <a href = "https://twitter.com/martisamuser/status/1518515944813101056?s=20&t=pACvyE-jT4DJB8SSwCdhaw">JOV paper in brief</a>
</div>

[//]: # (Project with Peelen)

<div class="p_post">
  <h3 class="p_post_h">Bodies as features in visual search</h3>
  <img class="p_post" src="{{site.url}}/assets/bod-attn.png" height="200">
  <b>With:</b> <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> Are high-level visual features prioritised, via feature-based attention, spatially-globally? We found attentional gain modulation of the fMRI representations of body silhouettes, presented in task-irrelevant locations, in high-level visual cortex. <br>
  <b>Publication:</b> <a href="https://doi.org/10.1016/j.neuroimage.2022.119207">NeuroImage'22 paper</a><br>
  <b>Comments:</b> <a href = "https://twitter.com/martisamuser/status/1516689822374854658?s=20&t=y4kGCWUn68jnxha1U0ZqUA">NeuroImage paper in brief</a>, <a href = "https://doi.org/10.17605/OSF.IO/HJ5VC">Code + Data</a>
</div>

<h3>
<div class="p_year">
  2021
</div>
</h3>

[//]: # (Project with Giacomo and Tim)

<div class="p_post">
  <h3 class="p_post_h">Recurrent operations in neural networks trained to recognise objects</h3>
  <img class="p_post" src="{{site.url}}/assets/rnn-filter.png" height="200">
  <b>With:</b> <a href="https://scholar.google.co.in/citations?user=qVvqArkAAAAJ&hl=en&oi=ao">Giacomo Aldegheri</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> In a recurrent neural network trained for object categorization, the recurrent flow carries category-orthogonal object feature (e.g. object location) information, which is used, iteratively, to constrain the subsequent inferences about the object's category.<br>
  <b>Publication:</b> <a href = "https://arxiv.org/abs/2111.07898">SVRHM'21 paper</a><br>
  <b>Comments:</b> <a href="https://twitter.com/martisamuser/status/1460631750640422912?s=20">SVRHM paper in brief</a>
</div>

<h3>
<div class="p_year">
  2019
</div>
</h3>

[//]: # (Project with Giacomo, Peelen and Marcel)

<div class="p_post">
  <h3 class="p_post_h">The function of early task-based modulations in object detection</h3>
  <img class="p_post" src="{{site.url}}/assets/SwitchSchem.png" height="200">
  <b>With:</b> <a href="https://scholar.google.co.in/citations?user=qVvqArkAAAAJ&hl=en&oi=ao">Giacomo Aldegheri</a>, <a href="https://scholar.google.nl/citations?user=sX0ZypwAAAAJ&hl=en&oi=ao">Marcel van Gerven</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> Task-based modulation of early visual processing in neural networks alleviates subsequent capacity limits caused by task and neural constraints.  Bias/gain modulation of neural activations can be linked to tapping into a superposition of networks. Optimised neural modulations are <i>not</i> <a href="https://doi.org/10.1016/j.cub.2004.04.028">feature-similarity gain modulations</a>. <br>
  <b>Publications:</b> <a href="https://sushrutthorat.com/ccn18/">CCN'18 paper</a>, <a href="https://arxiv.org/abs/1907.12309">CCN'19 paper</a><br>
</div>

[//]: # (Project with Ilze, Sjoerd, and Peelen)

<div class="p_post">
  <h3 class="p_post_h">The influence of scene information on object processing</h3>
  <img class="p_post" src="{{site.url}}/assets/sc-obj.png" height="200">
  <b>With:</b> <a href="https://www.linkedin.com/in/ilzethoonen/">Ilze Thoonen</a>, <a href="https://www.semanticscholar.org/author/Sjoerd-W.-Meijer/2061386172">Sjoerd Meijer</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> Task-irrelevant scene information biases categorization response towards co-varying objects (e.g. cars on roads). However, no evidence is found, across 4 experiments, for task-irrelevant scene information boosting the sensitivity of detecting co-varying objects. Further experimentation is required for validating these observations. <br>
  <b>Comments:</b> <a href="https://doi.org/10.6084/m9.figshare.9804725.v2">Summary presentation</a><br>
</div>

[//]: # (Project with Peelen)

<div class="p_post">
  <h3 class="p_post_h">The nature of the animacy organization in human ventral temporal cortex</h3>
  <img class="p_post" src="{{site.url}}/assets/anim_proj.png" height="200">
  <b>With:</b> <a href="https://scholar.google.it/citations?user=5GQjAZkAAAAJ&hl=en&oi=ao">Daria Proklova</a>, <a href="https://scholar.google.nl/citations?user=v4CvWHgAAAAJ&hl=en">Daniel Kaiser</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> The animacy organisation in the ventral temporal cortex is not fully driven by visual feature differences (modelled with a CNN). It also depends on non-visual (inferred) factors such as agency (quantified through a behavioural task).<br>
  <b>Publications:</b> <a href="https://doi.org/10.7554/eLife.47142">eLife'19 paper</a>, <a href="https://doi.org/10.6084/m9.figshare.5919154.v1">Masters Thesis</a> <br>
  <b>Comments:</b> <a href="https://twitter.com/abc_aalto/status/855043613453058048?s=20">Masters thesis in brief</a>, <a href="https://twitter.com/martisamuser/status/1171381533128777728?s=20">eLife paper in brief</a><br>
</div>

{% comment %}
<div class="p_post">
  <h3 class="p_post_h">Short Project Title</h3>
  <b>With:</b> Contributors<br>
  Comments / Further links
</div>
{% endcomment %}

<h3>
<div class="p_year">
  2016
</div>
</h3>

[//]: # (Project with Varad, RD)

<div class="p_post">
  <h3 class="p_post_h">Reverse dictionary using a word-definition based graph search</h3>
  <img class="p_post" src="{{site.url}}/assets/revmap.png" height="200">
  <b>With:</b> <a href="https://www.linkedin.com/in/vardos/">Varad Choudhari</a> <br>
  <b>Summary:</b> A method to process any forward word dictionary to build a reverse dictionary, using a n-hop reverse search on a graph, through word definitions. Performs as well as the state-of-the-art on a 3k lexicon. Doesn't scale well to 80k.<br>
  <b>Publication:</b> <a href="https://arxiv.org/abs/1606.00025">COLING'16 Paper</a><br>
  <b>Comments:</b> <a href="{{site.url}}/2016/11/06/reverse-dictionary">COLING paper in brief</a><br>
</div>

<h3>
<div class="p_year">
  2015
</div>
</h3>

[//]: # (Project with Bipin, IJCNN)

<div class="p_post">
  <h3 class="p_post_h">A Spiking Neural Network as a Quadcopter Flight Controller</h3>
  <img class="p_post" src="{{site.url}}/assets/btp.png" height="200">
  <b>With:</b> <a href="https://in.linkedin.com/in/sukanya-patil-b45009107">Sukanya Patil</a>, <a href="https://scholar.google.com/citations?user=QDEeC8EAAAAJ&hl=en">Bipin Rajendran</a> <br>
  <b>Summary:</b> <i>a</i>. Model-based control system for quadcopters towards velocity-waypoint navigation.<br> <i>b</i>. Modular SNNs for real-time arithmetic operations, using plastic synapses. SNNs are hard to tame!<br>
  <b>Publications:</b> <a href="{{site.url}}/assets/15_ijcnn.pdf">IJCNN'15 paper</a>, <a href="https://dx.doi.org/10.6084/m9.figshare.1582657.v1">B.Tech. Thesis</a><br>
  <b>Comments:</b> <a href="{{site.url}}/2016/06/05/quadcopter-control-using-snn">Thesis rumination</a>, <a href="{{site.url}}/2016/06/09/arithmetic-computation">IJCNN paper in brief</a><br>
</div>

{% comment %}
<h3>
<div class="p_year">
  Dormant
</div>
</h3>
{% endcomment %}

{% comment %}
<div class="p_post">
  <h3 class="p_post_h">Project Title</h3>
  <img class="p_post_i" src="http://placehold.it/200x200">
  <b>With:</b> Contributors <br>
  <b>Summary:</b><br><br><br><br><br><br>
  Publication (if any) <br>
  Comments / Further links
</div>
{% endcomment %}
