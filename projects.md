---
layout: page
title: Projects
---

<p class="message">
  Find information about my current and past projects below - grouped by topic.<br>
  Where applicable, collaborators leading those projects are <b><u>highlighted</u></b>.<br>
  My peer-reviewed and preprint publications can be found on <a href="https://scholar.google.it/citations?user=MPFzJQgAAAAJ&hl=en">Google Scholar</a>.<br>
  All my project reports and presentations are hosted at <a href="https://figshare.com/authors/Sushrut_Thorat/522624">figshare</a>.
</p>

<details>
  <summary class="p_year">
  Learning - Developmental & Lifelong
</summary>

<!-- (Project with Zejin, Tim, Radek) -->

<div class="p_post">
  <h3 class="p_post_h">Shape/texture bias in brains and machines</h3>
  <b>With:</b> <a href="https://scholar.google.nl/citations?user=MnURMg0AAAAJ&hl=en&oi=ao"><u>Zejin Lu</u></a>, <a href="https://scholar.google.nl/citations?user=XZtcvyEAAAAJ">Radoslaw Cichy</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> Building off <a href="https://openreview.net/forum?id=Bygh9j09KX">Geirhos et al. 2018</a>, where CNNs were shown to be texture-biased as compared to humans, we redefine the shape bias metric and assess the influence of recurrent processing and developmental trajectories on the shape bias in RNNs and humans.<br>
</div>

<!-- (Project with Rowan, Daniel, and Tim) -->

<div class="p_post">
  <h3 class="p_post_h">Flexible rule learning in brains and machines</h3>
  <b>With:</b> <a href="https://www.semanticscholar.org/author/R.-Sommers/114455459"><b><u>Rowan Sommers</u></b></a>, <a href="https://scholar.google.com/citations?user=YPdEhboAAAAJ&hl=en&oi=ao">Daniel Anthes</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> Inspired by the Wisconsin Card Sorting Task, we study the priors needed for neural networks to learn object/scene-specific rules continually, and relate their behaviors to human behavior on the same tasks.<br>
</div>

<!-- (Project with Daniel, Tim, and Peter) -->

<div class="p_post">
  <h3 class="p_post_h">Representational drift in macaque visual cortex</h3>
  <b>With:</b> <a href="https://scholar.google.com/citations?user=YPdEhboAAAAJ&hl=en&oi=ao"><b><u>Daniel Anthes</u></b></a>, <a href="https://scholar.google.nl/citations?user=Ieubd0EAAAAJ&hl=en&oi=ao">Peter König</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> Employing tools developed during our investigations into continual learning, we study if representational drift occurs in macaque visual cortex and how that multi-area system deals with changing representations.<br>
</div>

<!-- (Project with Daniel, Tim, and Peter) -->

<div class="p_post">
  <h3 class="p_post_h">Structured representational drift aids continual learning</h3>
  <img class="p_post" src="{{site.url}}/assets/rdac.png" height="200">
  <b>With:</b> <a href="https://scholar.google.com/citations?user=YPdEhboAAAAJ&hl=en&oi=ao"><b><u>Daniel Anthes</u></b></a>, <a href="https://scholar.google.nl/citations?user=Ieubd0EAAAAJ&hl=en&oi=ao">Peter König</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> In contemporary continual learning, readout misalignment due to learning-induced representational drift poses a big problem. However, constraining this drift to the readout null-space helps networks be both stable and plastic. <br>
  <b>Publication:</b> <a href="https://2023.ccneuro.org/proceedings/0000748.pdf">CCN'23 paper</a>, <a href="https://arxiv.org/abs/2310.04741">CoLLAs'24 paper</a><br>
  <b>Comments:</b> <a href="https://x.com/AnthesDaniel/status/1717913109795410403?s=20">CCN paper in brief</a>, <a href = "https://2024.ccneuro.org/pdf/567_Paper_authored_CCN2024-authored.pdf"> new analyses @ CCN'24 </a>
</div>

<!-- (Project with Gen and Peelen) -->

<div class="p_post">
  <h3 class="p_post_h">Statistical learning of distractor co-occurrences facilitates visual search</h3>
  <img class="p_post" src="{{site.url}}/assets/obj_grp.png" height="200">
  <b>With:</b> <a href="https://scholar.google.com/citations?user=2ToC6n4AAAAJ&hl=en">Genevieve Quek</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> Efficient visual search relies on the co-occurrence statistics of distractor shapes. Increased search efficiency among co-occurring distractors is probably driven by faster and/or more accurate rejection of a distractor's partner as a possible target.<br>
  <b>Publication:</b> <a href = "https://doi.org/10.1167/jov.22.10.2">JOV'22 paper</a><br>
  <b>Comments:</b> <a href = "https://twitter.com/martisamuser/status/1518515944813101056?s=20&t=pACvyE-jT4DJB8SSwCdhaw">JOV paper in brief</a>
</div>

</details>

<details>
  <summary class="p_year">
  Attentional Processes
</summary>

<!-- (Project with Johannes and Tim) -->

<div class="p_post">
  <h3 class="p_post_h">Multi-area readouts in brains and machines</h3>
  <b>With:</b> <a href="https://scholar.google.com/citations?user=z558t4EAAAAJ&hl=en&oi=ao"><b><u>Johannes Singer</u></b></a>, <a href="https://scholar.google.nl/citations?user=XZtcvyEAAAAJ">Radoslaw Cichy</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> Given observations in <a href="https://doi.org/10.1038/s41467-019-11448-7">Birman & Gardner 2019</a> and <a href="https://www.biorxiv.org/content/10.1101/2023.06.15.545065v1.abstract">Yeh et al. 2023</a>, we study if readout from multiple areas, in the human visual cortex and ANNs, is useful in performing classification tasks. <br>
  <b>Comments:</b> <a href="https://2024.ccneuro.org/pdf/98_Paper_authored_submission_non_anonymous.pdf">Preliminary results</a> were presented at CCN'24
</div>

<!-- (Project with Lotta) -->

<div class="p_post">
  <h3 class="p_post_h">Assessing the emergence of an attention schema in object tracking</h3>
  <img class="p_post" src="{{site.url}}/assets/ast_schema.png" height="200">
  <b>With:</b> <a href="https://github.com/lolotta"><u>Lotta Piefke</u></a>, <a href="https://scholar.google.ch/citations?user=YA6DPIcAAAAJ&hl=en">Adrien Doerig</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> In tracking an object through clutter with spatial attention, with RL, an agent learns to create an explicit encoding of the attentional state - an attention schema. This schema is most useful when the attentional state cannot be inferred from the stimulus.<br>
  <b>Publication:</b> <a href="https://escholarship.org/uc/item/1516x0js">CogSci'24 paper</a><br>
  <b>Comments:</b> <a href="https://x.com/lolotta6/status/1815370164600246348">CogSci paper in brief</a>
</div>

<!-- (Project with Surya and Peelen) -->

<div class="p_post">
  <h3 class="p_post_h">Size-dependence of object search templates in natural scenes</h3>
  <img class="p_post" src="{{site.url}}/assets/size-search.png" height="200">
  <b>With:</b> <a href="https://scholar.google.nl/citations?hl=en&user=D0z0dcgAAAAJ"><b><u>Surya Gayet</u></b></a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a>, et al.<br>
  <b>Summary:</b> Object size varies with the location of the object in scenes. During search for an object, in addition to the object's identity, the attentional template contains information its size, entangled with its identity, which is inferred from its location in the scene.<br>
  <b>Publication:</b> <a href="https://psycnet.apa.org/doi/10.1037/xhp0001172">JEP:HPP'24 paper</a><br>
  <b>Comments:</b> <a href="https://x.com/SuryaGayet/status/1763881177415364740?s=20">JEP:HPP paper in brief</a>
</div>

<!-- (Project with Peelen) -->

<div class="p_post">
  <h3 class="p_post_h">Bodies as features in visual search</h3>
  <img class="p_post" src="{{site.url}}/assets/bod-attn.png" height="200">
  <b>With:</b> <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> Are high-level visual features prioritised, via feature-based attention, spatially-globally? We found attentional gain modulation of the fMRI representations of body silhouettes, presented in task-irrelevant locations, in high-level visual cortex. <br>
  <b>Publication:</b> <a href="https://doi.org/10.1016/j.neuroimage.2022.119207">NeuroImage'22 paper</a><br>
  <b>Comments:</b> <a href = "https://twitter.com/martisamuser/status/1516689822374854658?s=20&t=y4kGCWUn68jnxha1U0ZqUA">NeuroImage paper in brief</a>, <a href = "https://doi.org/10.17605/OSF.IO/HJ5VC">Code + Data</a>
</div>

<!-- (Project with Giacomo, Peelen and Marcel) -->

<div class="p_post">
  <h3 class="p_post_h">The function of early task-based modulations in object detection</h3>
  <img class="p_post" src="{{site.url}}/assets/SwitchSchem.png" height="200">
  <b>With:</b> <a href="https://scholar.google.co.in/citations?user=qVvqArkAAAAJ&hl=en&oi=ao">Giacomo Aldegheri</a>, <a href="https://scholar.google.nl/citations?user=sX0ZypwAAAAJ&hl=en&oi=ao">Marcel van Gerven</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> Task-based modulation of early visual processing in neural networks alleviates subsequent capacity limits caused by task and neural constraints.  Bias/gain modulation of neural activations can be linked to tapping into a superposition of networks. Optimised neural modulations are <i>not</i> <a href="https://doi.org/10.1016/j.cub.2004.04.028">feature-similarity gain modulations</a>. <br>
  <b>Publications:</b> <a href="https://sushrutthorat.com/ccn18/">CCN'18 paper</a>, <a href="https://arxiv.org/abs/1907.12309">CCN'19 paper</a><br>
</div>

<!-- (Project with Ilze, Sjoerd, and Peelen) -->

<div class="p_post">
  <h3 class="p_post_h">The influence of scene information on object processing</h3>
  <img class="p_post" src="{{site.url}}/assets/sc-obj.png" height="200">
  <b>With:</b> <a href="https://www.linkedin.com/in/ilzethoonen/">Ilze Thoonen</a>, <a href="https://www.semanticscholar.org/author/Sjoerd-W.-Meijer/2061386172">Sjoerd Meijer</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> Task-irrelevant scene information biases categorization response towards co-varying objects (e.g. cars on roads). However, no evidence is found, across 4 experiments, for task-irrelevant scene information boosting the sensitivity of detecting co-varying objects. Further experimentation is required for validating these observations. <br>
  <b>Comments:</b> <a href="https://doi.org/10.6084/m9.figshare.9804725.v2">Summary presentation</a><br>
</div>

</details>

<details>
  <summary class="p_year">
  Recurrent Computations
</summary>

<!-- (Project with Jonas Bieber) -->

<div class="p_post">
  <h3 class="p_post_h">Decision-making RNNs</h3>
  <b>With:</b> <u>Jonas Bieber</u>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> Human categorisation reaction times can be <i>inferred</i> from RNN representations/outputs (<a href="https://doi.org/10.1371/journal.pcbi.1008215">Spoerer et al. 2020</a>, <a href="https://openreview.net/forum?id=1xPsn2gCOe">Goetschalckx et al. 2023</a>). Instead, we explore whether RNNs can <i>generate</i> RTs that are comparable to human RTs.<br>
</div>

<!-- (Project with Adrien and Tim) -->

<div class="p_post">
  <h3 class="p_post_h">How does recurrence interact with feedforward processing in RNNs?</h3>
  <img class="p_post" src="{{site.url}}/assets/blt_arrangement.png" height="200">
  <b>With:</b> <a href="https://scholar.google.ch/citations?user=YA6DPIcAAAAJ&hl=en">Adrien Doerig</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> In RNNs performing image classification, the feedforward sweep instantiates a representational arrangement that dovetails with the recurrence-induced "equal movement for all representations" prior, allowing classifications to be corrected.<br>
  <b>Publication:</b> <a href="https://arxiv.org/abs/2308.12435">CCN'23 paper</a><br>
  <b>Comments:</b> <a href="https://x.com/martisamuser/status/1712812776790311293?s=20">CCN paper in brief</a>
</div>

<!-- (Project with Giacomo and Tim) -->

<div class="p_post">
  <h3 class="p_post_h">Recurrent operations in neural networks trained to recognise objects</h3>
  <img class="p_post" src="{{site.url}}/assets/rnn-filter.png" height="200">
  <b>With:</b> <a href="https://scholar.google.co.in/citations?user=qVvqArkAAAAJ&hl=en&oi=ao">Giacomo Aldegheri</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> In a recurrent neural network trained for object categorization, the recurrent flow carries category-orthogonal object feature (e.g. object location) information, which is used, iteratively, to constrain the subsequent inferences about the object's category.<br>
  <b>Publication:</b> <a href = "https://arxiv.org/abs/2111.07898">SVRHM'21 paper</a><br>
  <b>Comments:</b> <a href="https://twitter.com/martisamuser/status/1460631750640422912?s=20">SVRHM paper in brief</a>
</div>

</details>

<details>
  <summary class="p_year">
  Visual Representations
</summary>

<!-- (Project with Adrien, Carmen, Tim) -->

<div class="p_post">
  <h3 class="p_post_h">Relational representations via gaze stitching</h3>
  <b>With:</b> <u>Jonas Jocham</u>, <a href="https://scholar.google.ch/citations?user=YA6DPIcAAAAJ&hl=en">Adrien Doerig</a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a><br>
  <b>Summary:</b> Inspired by <a href="https://doi.org/10.1016/j.pneurobio.2019.101717">Summerfield et al. 2020</a>, research on RF remapping, and predictive vision, we evaluate the usefulness of predicting the content of the next gaze towards generating scene representations that bear relational information about its constituents.<br>
</div>

<!-- (Project with Jochem, Gen, and Peelen) -->

<div class="p_post">
  <h3 class="p_post_h">Perception of rare inverted letters among upright ones</h3>
  <img class="p_post" src="{{site.url}}/assets/letter_illusion.png" height="200">
  <b>With:</b> <a href="https://www.linkedin.com/in/jochem-koopmans-051571236"><b><u>Jochem Koopmans</u></b></a>, <a href="https://scholar.google.com/citations?user=2ToC6n4AAAAJ&hl=en">Genevieve Quek</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> In a Sperling-like task where the letters are mostly upright, there is a general tendency to report occasionally-present and absent inverted letters as upright to the same extent. Previously reported expectation-driven illusions might be post-perceptual.<br>
  <b>Comments:</b> Jochem's masters thesis. Paper in prep.<br><br>
</div>

<!-- (Project with Victoria, Daniel, Tim, and Peter, etc.) -->

<div class="p_post">
  <h3 class="p_post_h">Brain reading with a Transformer</h3>
  <b>With:</b> <a href="https://www.linkedin.com/in/victoria-bosch/?originalSubdomain=nl"><b><u>Victoria Bosch</u></b></a>, <a href="https://scholar.google.com/citations?user=JXcWFkgAAAAJ&hl=en">Tim Kietzmann</a>, et al.<br>
  <b>Summary:</b> Using fMRI responses to natural scenes to condition the sentence generation in a Transformer, we study the neural underpinnings of scene semantics (objects and their relationships) encoded in natural language.<br>
  <b>Comments:</b> <a href="https://2024.ccneuro.org/pdf/526_Paper_authored_Cortext_Bosch_CCN2024.pdf">Preliminary results</a> were presented at CCN'24
</div>

<!-- (Project with Lu-Chun and Peelen) -->

<div class="p_post">
  <h3 class="p_post_h">Task-dependent characteristics of neural multi-object processing</h3>
  <img class="p_post" src="{{site.url}}/assets/vs-neural.png" height="200">
  <b>With:</b> <a href="https://scholar.google.nl/citations?hl=en&user=3Fj2iKkAAAAJ"><b><u>Lu-Chun Yeh</u></b></a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> The association between the neural processing of multi-object displays and the representations of those objects presented in isolation is task-dependent: same/different judgement relates to earlier, and object search to later stages in MEG/fMRI signals.<br>
  <b>Publication:</b> <a href="https://doi.org/10.1523/JNEUROSCI.1107-23.2024">JNeurosci'24 paper</a><br>
  <b>Comments:</b> <a href="https://x.com/LuChunYeh/status/1771482781337387299?s=20">JNeurosci paper in brief</a>
</div>

<!-- (Project with Peelen) -->

<div class="p_post">
  <h3 class="p_post_h">The nature of the animacy organization in human ventral temporal cortex</h3>
  <img class="p_post" src="{{site.url}}/assets/anim_proj.png" height="200">
  <b>With:</b> <a href="https://scholar.google.it/citations?user=5GQjAZkAAAAJ&hl=en&oi=ao">Daria Proklova</a>, <a href="https://scholar.google.nl/citations?user=v4CvWHgAAAAJ&hl=en">Daniel Kaiser</a>, <a href="https://scholar.google.nl/citations?user=IX0uaEQAAAAJ&hl=en&oi=ao">Marius Peelen</a><br>
  <b>Summary:</b> The animacy organisation in the ventral temporal cortex is not fully driven by visual feature differences (modelled with a CNN). It also depends on non-visual (inferred) factors such as agency (quantified through a behavioural task).<br>
  <b>Publications:</b> <a href="https://doi.org/10.7554/eLife.47142">eLife'19 paper</a>, <a href="https://doi.org/10.6084/m9.figshare.5919154.v1">Masters Thesis</a> <br>
  <b>Comments:</b> <a href="https://twitter.com/abc_aalto/status/855043613453058048?s=20">Masters thesis in brief</a>, <a href="https://twitter.com/martisamuser/status/1171381533128777728?s=20">eLife paper in brief</a><br>
</div>

</details>

<details>
  <summary class="p_year">
  Engineering Computational Systems
</summary>

<!-- (Project with Varad, RD) -->

<div class="p_post">
  <h3 class="p_post_h">Reverse dictionary using a word-definition based graph search</h3>
  <img class="p_post" src="{{site.url}}/assets/revmap.png" height="200">
  <b>With:</b> <a href="https://www.linkedin.com/in/vardos/">Varad Choudhari</a> <br>
  <b>Summary:</b> A method to process any forward word dictionary to build a reverse dictionary, using a n-hop reverse search on a graph, through word definitions. Performs as well as the state-of-the-art on a 3k lexicon. Doesn't scale well to 80k.<br>
  <b>Publication:</b> <a href="https://arxiv.org/abs/1606.00025">COLING'16 Paper</a><br>
  <b>Comments:</b> <a href="{{site.url}}/2016/11/06/reverse-dictionary">COLING paper in brief</a><br>
</div>

<!-- (Project with Bipin, IJCNN) -->

<div class="p_post">
  <h3 class="p_post_h">A Spiking Neural Network as a Quadcopter Flight Controller</h3>
  <img class="p_post" src="{{site.url}}/assets/btp.png" height="200">
  <b>With:</b> <a href="https://in.linkedin.com/in/sukanya-patil-b45009107">Sukanya Patil</a>, <a href="https://scholar.google.com/citations?user=QDEeC8EAAAAJ&hl=en">Bipin Rajendran</a> <br>
  <b>Summary:</b> <i>a</i>. Model-based control system for quadcopters towards velocity-waypoint navigation.<br> <i>b</i>. Modular SNNs for real-time arithmetic operations, using plastic synapses. SNNs are hard to tame!<br>
  <b>Publications:</b> <a href="{{site.url}}/assets/15_ijcnn.pdf">IJCNN'15 paper</a>, <a href="https://dx.doi.org/10.6084/m9.figshare.1582657.v1">B.Tech. Thesis</a><br>
  <b>Comments:</b> <a href="{{site.url}}/2016/06/05/quadcopter-control-using-snn">Thesis rumination</a>, <a href="{{site.url}}/2016/06/09/arithmetic-computation">IJCNN paper in brief</a><br>
</div>

</details>

{% comment %}
<h3>
<div class="p_year">
  Dormant
</div>
</h3>
{% endcomment %}

{% comment %}
<div class="p_post">
  <h3 class="p_post_h">Project Title</h3>
  <img class="p_post_i" src="http://placehold.it/200x200">
  <b>With:</b> Contributors <br>
  <b>Summary:</b><br><br><br><br><br><br>
  Publication (if any) <br>
  Comments / Further links
</div>
{% endcomment %}

{% comment %}

Students supervised:

1. Sjoerd Meijer, Ilse Thoonen, Ingrid Mulder, Loes Tonnissen -> bachelor's thesis 2018
2. Lieke van der Velden, Joep Willems, Stefan Long -> bachelor's thesis 2018
3. Jochem Koopmans -> masters thesis 2020
4. Lotta Pfieke -> bachelor's thesis 2023
5. Nicolle Rogalla -> bachelor's thesis 2023
6. Thomas Nortmann, Andrei Klimenok -> masters's projects 2023
7. Daniel Anthes, Zejin Lu, Johannes Singer -> PhD projects 2023
8. Jonas Bieber -> bachelor's thesis 2024

{% endcomment %}

